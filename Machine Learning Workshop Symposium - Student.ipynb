{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning with Python\n",
    "\n",
    "Sign-in page: https://goo.gl/forms/jmpV6Rhb2t9ef3Hl1\n",
    "\n",
    "Now that we've learned how to acquire, clean, and visualize our data, let's start doing some machine learning. Throughout this workshop, we will be using a Python package called scikit-learn. It is surprisingly easy to implement machine learning algorithms using scikit-learn, and in fact much of the work is done for you. Often, it is the acquisition and structuring of the data itself that requires the most finesse. Because of this, we will be working with pre-processed data to illustrate just how simple machine learning can be using scikit-learn. \n",
    "\n",
    "Before we dive in, let's start with some background on machine learning. There are two main types of machine learning algorithms: **supervised** and **unsupervised**. The goal of **supervised learning** is to train a model to classify data against a set of labels. For instance, we can train a model to separate images according to whether or not the image contains a face. In this case, the two labels would be *face* and *no face*. The presence of labeled training data is a huge advantage in machine learning, however it is not always available.\n",
    "\n",
    "When labeled training data is unavailable, we must use **unsupervised learning**. The goal of unsupervised learning is to train a model to extract *meaningful features* from the data. These meaningful features are often common patterns which are useful for compressing the information contained in the data. For example, in speech recognition, individual phonemes serve as meaningful features from which it is possible to reconstruct words independently of their tone or pitch. In computer vision, oriented edge-detectors are often the best features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognition\n",
    "\n",
    "In the first half of this workshop, we'll be using a very important supervised machine learning algorithm called the **support vector machine** to classify handwritten digits. This is a very well-studied problem in the machine learning community, and serves as a great starting point. First, let's import scikit-learn and a couple other modules we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import necessary modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sklearn comes with a few preloaded datasets, so let's load up the handwritten digits dataset. This is a list of pixel intensities corresponding to images of handwritten digits plus their associated labels (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use matplotlib to see what one of these images looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, matplotlib plots each value on a color scale. We can convert this to greyscale to get a better idea of the actual image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#other digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a better idea of what our data looks like, let's begin organizing it. An important concept in machine learning is overfitting. Overfitting typically occurs when a model has a large number of parameters, but not much data. An overfit model will perform very well on its training data, but will be unable to generalize beyond this training data.\n",
    "\n",
    "To prevent overfitting, we will split our dataset into two groups: training data and test data. This will allow us to evaluate how our model performs on data it's never seen before. This procedure is called cross-validation and is extremely important in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video describing SVM: https://www.youtube.com/watch?v=mA5nwGoRAOo\n",
    "\n",
    "From here, creating and training our classifier is relatively straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the accuracty of our classifier using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#score classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video describing C: https://www.youtube.com/watch?v=joTa_FeMZ2s\n",
    "\n",
    "Video describing gamma: https://www.youtube.com/watch?v=m2a2K4lprQw\n",
    "\n",
    "That's pretty impressive. So what are those mysterious values gamma and C? The C parameter controls the penalty for misclassification of each example in the training data. Large values of C highly penalize misclassification, and thus will fit to the training data more exactly. However, this can lead to overfitting and trouble with outliers, in which case a smaller value of C should be chosen.\n",
    "\n",
    "The gamma parameter is somewhat more complicated, but it can be understood to be the radius of influence of the individual support vectors. More info can be found in the sklearn SVM documentation: http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html\n",
    "\n",
    "So let's try changing the values of C and gamma and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change C and gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can automate the process of finding the best values of gamma and C (also known as hyperparameters) by using sklearn's built in grid-search function. Note that a new classifier must be built, trained, and evaluated for each combination of hyperparameters, so this process can be time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all! This was just a very small taste of machine learning with a simple example. We encourage you to explore the subject more deeply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
